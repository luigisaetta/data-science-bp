{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "036eabe4",
   "metadata": {},
   "source": [
    "### Regression and One-click deployment example (simplified., with new ADS functions)\n",
    "\n",
    "In this Notebook I walk through all the steps needed to develop a **regression model** and save the model to the OCI Data Science **Model Catalog**.\n",
    "\n",
    "After the model have been saved, I deploy the model as a **REST** service.\n",
    "\n",
    "The Notebook is based on the **California Housing Dataset**, downloaded from SKlearn.\n",
    "\n",
    "In this NB ADSTuner has been removed, training is done with best parameters from complete NB.\n",
    "\n",
    "This NB uses the new ADS functionality to simplify MOdel saving to Catalog. It requires ADS >= 2.5.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03e0c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "# the dataset used for the example\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# the GBM used\n",
    "import xgboost as xgb\n",
    "\n",
    "# to save to Model catalog\n",
    "import pickle\n",
    "import os\n",
    "from ads import set_auth\n",
    "import ads\n",
    "\n",
    "# for new ADS model deployment features we need this\n",
    "#\n",
    "from ads.model.framework.xgboost_model import XGBoostModel\n",
    "from ads.common.model_metadata import UseCaseType\n",
    "from ads.catalog.model import ModelCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aae34c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check we have the minimum ADS version (april 2022)\n",
    "assert ads.__version__ >= \"2.5.9\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5a7cf6",
   "metadata": {},
   "source": [
    "### some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4d7cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def get_general_info(data_df):\n",
    "    print(f\"There are: {len(data_df.columns)} columns in the dataset\")\n",
    "    print()\n",
    "    print(\n",
    "        \"The list of column names, in alphabetical order:\",\n",
    "        sorted(list(data_df.columns)),\n",
    "    )\n",
    "    print()\n",
    "    print(f\"There are {data_df.shape[0]} records in the dataset\")\n",
    "    print()\n",
    "    \n",
    "    return\n",
    "\n",
    "# well you have to decide a threshold in term of a fraction\n",
    "# to decide if the col is categorical\n",
    "FRAC = 0.1\n",
    "\n",
    "def analyze_df(data_df):\n",
    "    # it is ok to use isna, isnull is an alias of isna\n",
    "    missing_val = data_df.isna().sum()\n",
    "\n",
    "    # cardinality\n",
    "\n",
    "    THR = data_df.shape[0] * FRAC\n",
    "\n",
    "    list_card = []\n",
    "    list_cat = []\n",
    "    list_dtypes = []\n",
    "    list_num_zeros = []\n",
    "\n",
    "    for col in data_df.columns:\n",
    "        # count the # of distinct values\n",
    "        n_distinct = data_df[col].nunique()\n",
    "        list_card.append(n_distinct)\n",
    "        \n",
    "        # is categorical is decide on this rule\n",
    "        if n_distinct < THR:\n",
    "            # categorical\n",
    "            list_cat.append(\"Yes\")\n",
    "        else:\n",
    "            list_cat.append(\"No\")\n",
    "\n",
    "        list_dtypes.append(data_df[col].dtype)\n",
    "\n",
    "    # build the results DF\n",
    "    result_df = pd.DataFrame(\n",
    "        {\n",
    "            \"col_name\": list(data_df.columns),\n",
    "            \"missing_vals\": missing_val,\n",
    "            \"cardinality\": list_card,\n",
    "            \"is_categorical\": list_cat,\n",
    "            \"data_type\": list_dtypes,\n",
    "        },\n",
    "        index=None,\n",
    "    )\n",
    "\n",
    "    # if you don't want cols as index\n",
    "    result_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b75125",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b0ae5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "\n",
    "orig_df = housing.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdee61c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62ea12c",
   "metadata": {},
   "source": [
    "### some EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccbbbbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AveBedrms', 'AveOccup', 'AveRooms', 'HouseAge', 'MedInc', 'Population']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this example I'll use all the columns (ex MedHouseVal) as features, except Lat, Long, to simplify\n",
    "\n",
    "TARGET = \"MedHouseVal\"\n",
    "all_cols = list(orig_df.columns)\n",
    "cols_to_drop = ['Latitude', 'Longitude']\n",
    "\n",
    "cat_cols = ['HouseAge']\n",
    "\n",
    "# take care, I have sorted\n",
    "FEATURES = sorted(list(set(all_cols) - set([TARGET])- set(cols_to_drop)))\n",
    "\n",
    "# for LightGBM\n",
    "cat_columns_idxs = [i for i, col in enumerate(FEATURES) if col in cat_cols]\n",
    "\n",
    "FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed50c5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the only important thing is that we have 1 categorical column: HouseAge\n",
    "\n",
    "# we will code categorical as integer starting from zero\n",
    "# in this case it is easy, since the minimum is 1... so we need only to subtract 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "601b30b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy before any changes\n",
    "used_df = orig_df.copy()\n",
    "\n",
    "used_df['HouseAge'] = used_df['HouseAge'] - 1.\n",
    "\n",
    "used_df['HouseAge'] = used_df['HouseAge'].astype(int)\n",
    "used_df['HouseAge'] = used_df['HouseAge'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deb52302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make a simple train/test split\n",
    "X = used_df[FEATURES].values\n",
    "y = used_df[TARGET].values\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abad62f5",
   "metadata": {},
   "source": [
    "### Train with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aada11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 20min 12s, sys: 11.2 s, total: 1h 20min 23s\n",
      "Wall time: 2min 50s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.008, max_delta_step=0,\n",
       "             max_depth=7, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=600, n_jobs=32,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "### train with best params\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 600,\n",
    "    \"learning_rate\": 0.008,\n",
    "    \"max_depth\": 7,\n",
    "}\n",
    "\n",
    "model = xgb.XGBRegressor(**params)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f79f10f",
   "metadata": {},
   "source": [
    "### Prepare for Model Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cf7357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_ARTEFACT = f\"./model-files\"\n",
    "\n",
    "if not os.path.exists(PATH_ARTEFACT):\n",
    "    os.mkdir(PATH_ARTEFACT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a1a2d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_auth(auth='resource_principal')\n",
    "\n",
    "xgb_model = XGBoostModel(estimator=model, artifact_dir= PATH_ARTEFACT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "245ef4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. prepare\n",
    "xgb_model.prepare(\n",
    "    inference_conda_env=\"generalml_p37_cpu_v1\",\n",
    "    training_conda_env=\"generalml_p37_cpu_v1\",\n",
    "    use_case_type=UseCaseType.REGRESSION,\n",
    "    X_sample=X_test,\n",
    "    y_sample=y_test,\n",
    "    force_overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0759980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# be aware that the XGBModel is saved as a JSON file, in model-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "22f361f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model.json from model directory /home/datascience/data-science-bp/model-files ...\n",
      "Model is successfully loaded.\n",
      "{'prediction': [3.4311716556549072, 0.8633096814155579, 2.053156852722168, 1.4130446910858154, 3.0937297344207764, 2.868069648742676, 2.3109734058380127, 1.25899076461792, 1.4848921298980713, 1.584919810295105]}\n",
      "\n",
      "Expected: [3.55  0.707 2.294 1.125 2.254 2.63  2.268 1.662 1.18  1.563]\n"
     ]
    }
   ],
   "source": [
    "# 2. verify\n",
    "print(xgb_model.verify(X_test[:10]))\n",
    "\n",
    "# compare with expected values\n",
    "print()\n",
    "print(f\"Expected: {y_test[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5afdb7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Done</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Available</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Actions Needed\n",
       "Step      Status        Details                                                           \n",
       "initiate  Done          Initiated the model                                               \n",
       "prepare() Done          Generated runtime.yaml                                            \n",
       "                        Generated score.py                                                \n",
       "                        Serialized model                                                  \n",
       "                        Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Done          Local tested .predict from score.py                               \n",
       "save()    Available     Conducted Introspect Test                                         \n",
       "                        Uploaded artifact to model catalog                                \n",
       "deploy()  Not Available Deployed the model                                                \n",
       "predict() Not Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can check the list of steps\n",
    "xgb_model.summary_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "772930dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model.json', 'output_schema.json', 'input_schema.json', 'runtime.yaml', 'test_json_output.json', 'score.py']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test key</th>\n",
       "      <th>Test name</th>\n",
       "      <th>Result</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>runtime_env_path</td>\n",
       "      <td>Check that field MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is set</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>runtime_env_python</td>\n",
       "      <td>Check that field MODEL_DEPLOYMENT.INFERENCE_PYTHON_VERSION is set to a value of 3.6 or higher</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>runtime_path_exist</td>\n",
       "      <td>Check that the file path in MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is correct.</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>runtime_version</td>\n",
       "      <td>Check that field MODEL_ARTIFACT_VERSION is set to 3.0</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>runtime_yaml</td>\n",
       "      <td>Check that the file \"runtime.yaml\" exists and is in the top level directory of the artifact directory</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>score_load_model</td>\n",
       "      <td>Check that load_model() is defined</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>score_predict</td>\n",
       "      <td>Check that predict() is defined</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>score_predict_arg</td>\n",
       "      <td>Check that all other arguments in predict() are optional and have default values</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>score_predict_data</td>\n",
       "      <td>Check that the only required argument for predict() is named \"data\"</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>score_py</td>\n",
       "      <td>Check that the file \"score.py\" exists and is in the top level directory of the artifact directory</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>score_syntax</td>\n",
       "      <td>Check for Python syntax errors</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test key  \\\n",
       "0     runtime_env_path   \n",
       "1   runtime_env_python   \n",
       "2   runtime_path_exist   \n",
       "3      runtime_version   \n",
       "4         runtime_yaml   \n",
       "5     score_load_model   \n",
       "6        score_predict   \n",
       "7    score_predict_arg   \n",
       "8   score_predict_data   \n",
       "9             score_py   \n",
       "10        score_syntax   \n",
       "\n",
       "                                                                                                Test name  \\\n",
       "0                                             Check that field MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is set   \n",
       "1           Check that field MODEL_DEPLOYMENT.INFERENCE_PYTHON_VERSION is set to a value of 3.6 or higher   \n",
       "2                             Check that the file path in MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is correct.   \n",
       "3                                                   Check that field MODEL_ARTIFACT_VERSION is set to 3.0   \n",
       "4   Check that the file \"runtime.yaml\" exists and is in the top level directory of the artifact directory   \n",
       "5                                                                      Check that load_model() is defined   \n",
       "6                                                                         Check that predict() is defined   \n",
       "7                        Check that all other arguments in predict() are optional and have default values   \n",
       "8                                     Check that the only required argument for predict() is named \"data\"   \n",
       "9       Check that the file \"score.py\" exists and is in the top level directory of the artifact directory   \n",
       "10                                                                         Check for Python syntax errors   \n",
       "\n",
       "    Result Message  \n",
       "0   Passed          \n",
       "1   Passed          \n",
       "2   Passed          \n",
       "3   Passed          \n",
       "4   Passed          \n",
       "5   Passed          \n",
       "6   Passed          \n",
       "7   Passed          \n",
       "8   Passed          \n",
       "9   Passed          \n",
       "10  Passed          "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. introspect to do some checks\n",
    "xgb_model.introspect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0636194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems everything is OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4e3b07d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model.json from model directory /home/datascience/data-science-bp/model-files ...\n",
      "Model is successfully loaded.\n",
      "['model.json', 'output_schema.json', 'input_schema.json', 'runtime.yaml', 'test_json_output.json', 'score.py']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact:/tmp/saved_model_d1041770-283b-494a-af92-d9bd5facc598.zip\n"
     ]
    }
   ],
   "source": [
    "# 4. after all needed changes to score.py you can save to model catalog\n",
    "model_id = xgb_model.save(display_name = \"cal_housing_new2\", description = \"new way of model deployment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b063c05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Done</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Done</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>Available</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Actions Needed\n",
       "Step      Status        Details                                                           \n",
       "initiate  Done          Initiated the model                                               \n",
       "prepare() Done          Generated runtime.yaml                                            \n",
       "                        Generated score.py                                                \n",
       "                        Serialized model                                                  \n",
       "                        Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Done          Local tested .predict from score.py                               \n",
       "save()    Done          Conducted Introspect Test                                         \n",
       "                        Uploaded artifact to model catalog                                \n",
       "deploy()  Available     Deployed the model                                                \n",
       "predict() Not Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just to see, check again status\n",
    "xgb_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac32a0",
   "metadata": {},
   "source": [
    "### deploy to Model Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "72e90935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_auth(auth='resource_principal')\n",
    "\n",
    "# needs to specify shape, log ids... easier from the UI\n",
    "xgb_model_deployment = xgb_model.deploy(display_name = \"cal_xgb_deploy1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f7559f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:ads:ADS Exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/datascience/conda/generalml_p37_cpu_v1/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-65-ab7e74306387>\", line 1, in <module>\n",
      "    xgb_model.predict(X_test[:10])\n",
      "  File \"/home/datascience/conda/generalml_p37_cpu_v1/lib/python3.7/site-packages/ads/model/generic_model.py\", line 1108, in predict\n",
      "    raise NotActiveDeploymentError(current_state)\n",
      "ads.model.generic_model.NotActiveDeploymentError: To perform a prediction the deployed model needs to be in an active state. The current state is: UPDATING.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NotActiveDeploymentError: To perform a prediction the deployed model needs to be in an active state. The current state is: UPDATING."
     ]
    }
   ],
   "source": [
    "xgb_model.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbbb949",
   "metadata": {},
   "source": [
    "### Customize score.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e9bb3d",
   "metadata": {},
   "source": [
    "### Model introspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7bdab8",
   "metadata": {},
   "source": [
    "### Some tests on the code before saving to Model Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8346ccf",
   "metadata": {},
   "source": [
    "### Save to Model Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c8baf2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Done</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Done</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>UPDATING</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Actions Needed\n",
       "Step      Status        Details                                                           \n",
       "initiate  Done          Initiated the model                                               \n",
       "prepare() Done          Generated runtime.yaml                                            \n",
       "                        Generated score.py                                                \n",
       "                        Serialized model                                                  \n",
       "                        Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Done          Local tested .predict from score.py                               \n",
       "save()    Done          Conducted Introspect Test                                         \n",
       "                        Uploaded artifact to model catalog                                \n",
       "deploy()  UPDATING      Deployed the model                                                \n",
       "predict() Not Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.summary_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658abece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_cpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_cpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
