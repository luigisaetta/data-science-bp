{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc71f0c2",
   "metadata": {},
   "source": [
    "### Regression on California Housing Dataset\n",
    "\n",
    "I have **split** the initial demo in two Notebooks:\n",
    "* a first one, where I train the model (using XGBoost) and save the model in JSON format\n",
    "* this NB where the trained model, serialized as JSON, is saved to the Model Catalog and then deployed as REST service\n",
    "\n",
    "It requires ADS vers. >= 2.5.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c2d16dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# the dataset used for the example\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# the GBM used\n",
    "import xgboost as xgb\n",
    "\n",
    "import os\n",
    "from ads import set_auth\n",
    "import ads\n",
    "\n",
    "# for new ADS model deployment features we need this\n",
    "#\n",
    "from ads.model.framework.xgboost_model import XGBoostModel\n",
    "from ads.common.model_metadata import UseCaseType\n",
    "from ads.catalog.model import ModelCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba5402f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check we have the minimum ADS version (april 2022)\n",
    "assert ads.__version__ >= \"2.5.9\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50257f9",
   "metadata": {},
   "source": [
    "In this initial part the dataset is loaded and a test dataset i created, to use it to test the model after deployment.\n",
    "\n",
    "The (XGBoost) model is loaded from a JSON file produced by **train_california_housing_simplified** NB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0519dc57",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ad4ec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "\n",
    "orig_df = housing.frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a747c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec34c103",
   "metadata": {},
   "source": [
    "### some data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2f3e70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AveBedrms', 'AveOccup', 'AveRooms', 'HouseAge', 'MedInc', 'Population']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this example I'll use all the columns (ex MedHouseVal) as features, except Lat, Long, to simplify\n",
    "\n",
    "TARGET = \"MedHouseVal\"\n",
    "all_cols = list(orig_df.columns)\n",
    "cols_to_drop = ['Latitude', 'Longitude']\n",
    "\n",
    "cat_cols = ['HouseAge']\n",
    "\n",
    "# take care, I have sorted\n",
    "FEATURES = sorted(list(set(all_cols) - set([TARGET])- set(cols_to_drop)))\n",
    "\n",
    "# for LightGBM\n",
    "cat_columns_idxs = [i for i, col in enumerate(FEATURES) if col in cat_cols]\n",
    "\n",
    "FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d052d30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the only important thing is that we have 1 categorical column: HouseAge\n",
    "\n",
    "# we will code categorical as integer starting from zero\n",
    "# in this case it is easy, since the minimum is 1... so we need only to subtract 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8b991ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy before any changes\n",
    "used_df = orig_df.copy()\n",
    "\n",
    "used_df['HouseAge'] = used_df['HouseAge'] - 1.\n",
    "\n",
    "used_df['HouseAge'] = used_df['HouseAge'].astype(int)\n",
    "used_df['HouseAge'] = used_df['HouseAge'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07818da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make a simple train/test split\n",
    "X = used_df[FEATURES].values\n",
    "y = used_df[TARGET].values\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f677d3",
   "metadata": {},
   "source": [
    "### Load the model saved in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94477ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE_NAME = 'housing.json'\n",
    "\n",
    "model = xgb.Booster()\n",
    "\n",
    "model.load_model(MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1931e38d",
   "metadata": {},
   "source": [
    "### Prepare for Model Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78b95cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_ARTEFACT = f\"./model-files\"\n",
    "\n",
    "if not os.path.exists(PATH_ARTEFACT):\n",
    "    os.mkdir(PATH_ARTEFACT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6d2851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_auth(auth='resource_principal')\n",
    "\n",
    "xgb_model = XGBoostModel(estimator=model, artifact_dir= PATH_ARTEFACT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c276a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. prepare\n",
    "xgb_model.prepare(\n",
    "    inference_conda_env=\"generalml_p37_cpu_v1\",\n",
    "    training_conda_env=\"generalml_p37_cpu_v1\",\n",
    "    use_case_type=UseCaseType.REGRESSION,\n",
    "    X_sample=X_test,\n",
    "    y_sample=y_test,\n",
    "    force_overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8d04f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# be aware that the XGBModel is saved as a JSON file, in model-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddbe1ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model.json from model directory /home/datascience/data-science-bp/model-files ...\n",
      "Model is successfully loaded.\n",
      "{'prediction': [4.162364959716797, 3.1165318489074707, 3.8856496810913086, 1.3761677742004395, 3.2547011375427246, 1.7698906660079956, 1.7593719959259033, 3.1433591842651367, 0.922572135925293, 0.7925826907157898]}\n",
      "\n",
      "Expected: [5.    2.939 4.125 1.576 3.041 1.    2.187 2.581 0.714 0.838]\n"
     ]
    }
   ],
   "source": [
    "# 2. verify\n",
    "print(xgb_model.verify(X_test[:10]))\n",
    "\n",
    "# compare with expected values\n",
    "print()\n",
    "print(f\"Expected: {y_test[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a127737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Done</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Available</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Actions Needed\n",
       "Step      Status        Details                                                           \n",
       "initiate  Done          Initiated the model                                               \n",
       "prepare() Done          Generated runtime.yaml                                            \n",
       "                        Generated score.py                                                \n",
       "                        Serialized model                                                  \n",
       "                        Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Done          Local tested .predict from score.py                               \n",
       "save()    Available     Conducted Introspect Test                                         \n",
       "                        Uploaded artifact to model catalog                                \n",
       "deploy()  Not Available Deployed the model                                                \n",
       "predict() Not Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can check the list of steps\n",
    "xgb_model.summary_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c87d7317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model.json', 'output_schema.json', 'input_schema.json', 'runtime.yaml', 'test_json_output.json', 'score.py']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test key</th>\n",
       "      <th>Test name</th>\n",
       "      <th>Result</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>runtime_env_path</td>\n",
       "      <td>Check that field MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is set</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>runtime_env_python</td>\n",
       "      <td>Check that field MODEL_DEPLOYMENT.INFERENCE_PYTHON_VERSION is set to a value of 3.6 or higher</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>runtime_path_exist</td>\n",
       "      <td>Check that the file path in MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is correct.</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>runtime_version</td>\n",
       "      <td>Check that field MODEL_ARTIFACT_VERSION is set to 3.0</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>runtime_yaml</td>\n",
       "      <td>Check that the file \"runtime.yaml\" exists and is in the top level directory of the artifact directory</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>score_load_model</td>\n",
       "      <td>Check that load_model() is defined</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>score_predict</td>\n",
       "      <td>Check that predict() is defined</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>score_predict_arg</td>\n",
       "      <td>Check that all other arguments in predict() are optional and have default values</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>score_predict_data</td>\n",
       "      <td>Check that the only required argument for predict() is named \"data\"</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>score_py</td>\n",
       "      <td>Check that the file \"score.py\" exists and is in the top level directory of the artifact directory</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>score_syntax</td>\n",
       "      <td>Check for Python syntax errors</td>\n",
       "      <td>Passed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Test key  \\\n",
       "0     runtime_env_path   \n",
       "1   runtime_env_python   \n",
       "2   runtime_path_exist   \n",
       "3      runtime_version   \n",
       "4         runtime_yaml   \n",
       "5     score_load_model   \n",
       "6        score_predict   \n",
       "7    score_predict_arg   \n",
       "8   score_predict_data   \n",
       "9             score_py   \n",
       "10        score_syntax   \n",
       "\n",
       "                                                                                                Test name  \\\n",
       "0                                             Check that field MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is set   \n",
       "1           Check that field MODEL_DEPLOYMENT.INFERENCE_PYTHON_VERSION is set to a value of 3.6 or higher   \n",
       "2                             Check that the file path in MODEL_DEPLOYMENT.INFERENCE_ENV_PATH is correct.   \n",
       "3                                                   Check that field MODEL_ARTIFACT_VERSION is set to 3.0   \n",
       "4   Check that the file \"runtime.yaml\" exists and is in the top level directory of the artifact directory   \n",
       "5                                                                      Check that load_model() is defined   \n",
       "6                                                                         Check that predict() is defined   \n",
       "7                        Check that all other arguments in predict() are optional and have default values   \n",
       "8                                     Check that the only required argument for predict() is named \"data\"   \n",
       "9       Check that the file \"score.py\" exists and is in the top level directory of the artifact directory   \n",
       "10                                                                         Check for Python syntax errors   \n",
       "\n",
       "    Result Message  \n",
       "0   Passed          \n",
       "1   Passed          \n",
       "2   Passed          \n",
       "3   Passed          \n",
       "4   Passed          \n",
       "5   Passed          \n",
       "6   Passed          \n",
       "7   Passed          \n",
       "8   Passed          \n",
       "9   Passed          \n",
       "10  Passed          "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. introspect to do some checks\n",
    "xgb_model.introspect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a234326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems everything is OK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ecbf0a",
   "metadata": {},
   "source": [
    "### Save the Model to the Model Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43b01503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model.json from model directory /home/datascience/data-science-bp/model-files ...\n",
      "Model is successfully loaded.\n",
      "['model.json', 'output_schema.json', 'input_schema.json', 'runtime.yaml', 'test_json_output.json', 'score.py']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact:/tmp/saved_model_898864aa-3a41-4f6f-9d80-e9511b6c2c73.zip\n"
     ]
    }
   ],
   "source": [
    "# 4. after all needed changes to score.py you can save to model catalog\n",
    "model_id = xgb_model.save(display_name = \"cal_housing_new2\", description = \"new way of model deployment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "737b2fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Done</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Done</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>Available</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Actions Needed\n",
       "Step      Status        Details                                                           \n",
       "initiate  Done          Initiated the model                                               \n",
       "prepare() Done          Generated runtime.yaml                                            \n",
       "                        Generated score.py                                                \n",
       "                        Serialized model                                                  \n",
       "                        Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Done          Local tested .predict from score.py                               \n",
       "save()    Done          Conducted Introspect Test                                         \n",
       "                        Uploaded artifact to model catalog                                \n",
       "deploy()  Available     Deployed the model                                                \n",
       "predict() Not Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just to see, check again status\n",
    "xgb_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23ce945",
   "metadata": {},
   "source": [
    "### deploy the model as REST service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69c11e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_auth(auth='resource_principal')\n",
    "\n",
    "# needs to specify shape, log ids... (easier from the UI)\n",
    "xgb_model_deployment = xgb_model.deploy(display_name = \"cal_xgb_deploy1\",\n",
    "                                        deployment_instance_count=1,\n",
    "                                        deployment_instance_shape='VM.Standard2.2',\n",
    "                                        deployment_bandwidth_mbps=10,\n",
    "                                        # to attach logging to the REST service. OCID can be taken from UI\n",
    "                                        deployment_log_group_id=\"ocid1.loggroup.oc1.eu-frankfurt-1.amaaaaaangencdya63i3qhao4bjx754lb3m2jpekev5oc55p5ebjvykbtgya\"\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56298582",
   "metadata": {},
   "source": [
    "### test the deployed REST service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ea03579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': [4.162364959716797,\n",
       "  3.1165318489074707,\n",
       "  3.8856496810913086,\n",
       "  1.3761677742004395,\n",
       "  3.2547011375427246,\n",
       "  1.7698906660079956,\n",
       "  1.7593719959259033,\n",
       "  3.1433591842651367,\n",
       "  0.922572135925293,\n",
       "  0.7925826907157898]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7082bc58",
   "metadata": {},
   "source": [
    "### clean up the deployed REST service and the Model from the Catalog\n",
    "\n",
    "careful... it will be destroyed... are you sure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61ea40fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.delete_deployment(wait_for_completion=True)\n",
    "\n",
    "ModelCatalog(compartment_id=os.environ['NB_SESSION_COMPARTMENT_OCID']).delete_model(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2015df30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_cpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_cpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
