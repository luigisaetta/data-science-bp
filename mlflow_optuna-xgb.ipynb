{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9d9d30b",
   "metadata": {},
   "source": [
    "### MLFlow and Optuna\n",
    "In this Notebook we show how to use **Optuna** for hyper-parameters optimization and how to track the results of experiments inside **MLFlow**\n",
    "\n",
    "* env used: generalml_p37_gpu_v1\n",
    "* works also with CPU\n",
    "* requires: **pip install mlflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dd969c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import optuna\n",
    "import mlflow\n",
    "\n",
    "import xgboost as xgb \n",
    "\n",
    "# using a myconfig.py file I avoid to show passwords in the NB\n",
    "from myconfig import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb2477d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used ony as an example\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae707b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset\n",
    "\n",
    "# as dataset for the example of ML training we're suing Wisconsin Breast Cancer dataset\n",
    "# data can be loaded from sklearn\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# load in Pandas DataFrame\n",
    "df = pd.DataFrame(\n",
    "    np.c_[cancer[\"data\"], cancer[\"target\"]],\n",
    "    columns=np.append(cancer[\"feature_names\"], [\"target\"]),\n",
    ")\n",
    "\n",
    "TARGET = \"target\"\n",
    "\n",
    "# let's choose only some of the column\n",
    "FEATURES = [\"mean radius\", \"mean concavity\", \"mean symmetry\", \"mean fractal dimension\"]\n",
    "\n",
    "X = df[FEATURES].values\n",
    "y = df[TARGET].values\n",
    "\n",
    "dtrain = xgb.DMatrix(X, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d51ce4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Here we load the configuration to connect to MLFlow Tracking Server\n",
    "#\n",
    "\n",
    "# also the tracking server uri is in the myconfig.py file\n",
    "TRACK_SERVER_URI = config[\"TRACK_SERVER_URI\"]\n",
    "\n",
    "# the key for succesfull auth is to set these two variables\n",
    "# see documentation in https://www.mlflow.org/docs/latest/tracking.html\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = config[\"MLFLOW_TRACKING_USERNAME\"]\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = config['MLFLOW_TRACKING_PASSWORD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63c7e2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/02/17 11:05:17 INFO mlflow.tracking.fluent: Experiment with name 'exp-xgb-9' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "# initialize and set experiment ID\n",
    "mlflow.set_tracking_uri(TRACK_SERVER_URI)\n",
    "\n",
    "EXP_NAME = \"exp-xgb-9\"\n",
    "\n",
    "exp_id = mlflow.set_experiment(EXP_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45ad5ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Here we define what we do using Optuna\n",
    "#\n",
    "def objective(trial):\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        # tuning on max_depth, n_estimators for the example\n",
    "        param = {\n",
    "            \"verbosity\": 0,\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"error\",\n",
    "            \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\"]),\n",
    "            \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "        }\n",
    "        \n",
    "        if param[\"booster\"] == \"gbtree\" or param[\"booster\"] == \"dart\":\n",
    "            param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 9)\n",
    "            param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
    "            param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "            param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "        if param[\"booster\"] == \"dart\":\n",
    "            param[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
    "            param[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
    "            param[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n",
    "            param[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n",
    "        \n",
    "        # logging to MLFlow\n",
    "        mlflow.log_params(param)\n",
    "        \n",
    "        pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"test-error\")\n",
    "        \n",
    "        history = xgb.cv(param, dtrain, nfold=5, num_boost_round=80, callbacks=[pruning_callback])\n",
    "        \n",
    "        mean_error = history[\"test-error-mean\"].values[-1]\n",
    "        \n",
    "        # compute accuracy\n",
    "        acc = round(1. - mean_error, 4)\n",
    "        \n",
    "         # logging to MLFlow\n",
    "        mlflow.log_metric(\"acc\", acc)\n",
    "        \n",
    "        mlflow.end_run()\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0c0d0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-17 11:05:19,260]\u001b[0m A new study created in memory with name: exp-xgb-9\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:05:44,681]\u001b[0m Trial 0 finished with value: 0.8542 and parameters: {'booster': 'gblinear', 'lambda': 0.5249055144877295, 'alpha': 0.0016882829515764979}. Best is trial 0 with value: 0.8542.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:06:10,007]\u001b[0m Trial 1 finished with value: 0.9122 and parameters: {'booster': 'gblinear', 'lambda': 3.521681514362404e-08, 'alpha': 0.00010842315928163968}. Best is trial 1 with value: 0.9122.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:06:35,380]\u001b[0m Trial 2 finished with value: 0.9139 and parameters: {'booster': 'gblinear', 'lambda': 8.773774032777868e-07, 'alpha': 0.0001450515050880122}. Best is trial 2 with value: 0.9139.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:07:22,715]\u001b[0m Trial 3 finished with value: 0.9034 and parameters: {'booster': 'gbtree', 'lambda': 0.02479229370671492, 'alpha': 0.7966635544456746, 'max_depth': 3, 'eta': 9.227946692432297e-06, 'gamma': 0.00014528182275889048, 'grow_policy': 'lossguide'}. Best is trial 2 with value: 0.9139.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:07:48,000]\u001b[0m Trial 4 finished with value: 0.8647 and parameters: {'booster': 'gblinear', 'lambda': 0.21364001738837712, 'alpha': 0.0025439602189200466}. Best is trial 2 with value: 0.9139.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:08:13,414]\u001b[0m Trial 5 finished with value: 0.8911 and parameters: {'booster': 'gblinear', 'lambda': 0.0014162895912272048, 'alpha': 0.0013569236388544076}. Best is trial 2 with value: 0.9139.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:08:38,723]\u001b[0m Trial 6 finished with value: 0.8841 and parameters: {'booster': 'gblinear', 'lambda': 0.0041609037756012365, 'alpha': 0.005720932715228307}. Best is trial 2 with value: 0.9139.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:09:04,043]\u001b[0m Trial 7 finished with value: 0.8647 and parameters: {'booster': 'gblinear', 'lambda': 1.1919389984569236e-07, 'alpha': 0.06821462248543896}. Best is trial 2 with value: 0.9139.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:09:29,411]\u001b[0m Trial 8 finished with value: 0.8594 and parameters: {'booster': 'gblinear', 'lambda': 0.39896999762534807, 'alpha': 0.007875151295885053}. Best is trial 2 with value: 0.9139.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:09:32,354]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:09:39,769]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:10:05,162]\u001b[0m Trial 11 finished with value: 0.9087 and parameters: {'booster': 'gblinear', 'lambda': 1.055311864835946e-08, 'alpha': 1.6610382786427876e-05}. Best is trial 2 with value: 0.9139.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:10:07,211]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:10:32,567]\u001b[0m Trial 13 finished with value: 0.9087 and parameters: {'booster': 'gblinear', 'lambda': 1.3563738305238886e-08, 'alpha': 2.3308953719536276e-06}. Best is trial 2 with value: 0.9139.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:10:57,885]\u001b[0m Trial 14 finished with value: 0.9122 and parameters: {'booster': 'gblinear', 'lambda': 8.38125297045575e-05, 'alpha': 0.00014475488407178358}. Best is trial 2 with value: 0.9139.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:12:42,264]\u001b[0m Trial 15 finished with value: 0.9016 and parameters: {'booster': 'gbtree', 'lambda': 2.060779855407944e-07, 'alpha': 0.000126096693695427, 'max_depth': 8, 'eta': 1.154553533439568e-08, 'gamma': 0.9710014339469204, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 0.9139.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:13:07,600]\u001b[0m Trial 16 finished with value: 0.9104 and parameters: {'booster': 'gblinear', 'lambda': 4.611440336451196e-06, 'alpha': 1.6092591647683934e-06}. Best is trial 2 with value: 0.9139.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:13:32,970]\u001b[0m Trial 17 finished with value: 0.9087 and parameters: {'booster': 'gblinear', 'lambda': 8.622137185490903e-08, 'alpha': 1.671107669537259e-08}. Best is trial 2 with value: 0.9139.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:13:39,407]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:14:04,928]\u001b[0m Trial 19 finished with value: 0.8647 and parameters: {'booster': 'gblinear', 'lambda': 1.184822525997691e-06, 'alpha': 0.06380270888970956}. Best is trial 2 with value: 0.9139.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:14:30,403]\u001b[0m Trial 20 finished with value: 0.9017 and parameters: {'booster': 'gblinear', 'lambda': 0.0007582162851595782, 'alpha': 1.8175768159853266e-05}. Best is trial 2 with value: 0.9139.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:14:55,766]\u001b[0m Trial 21 finished with value: 0.9175 and parameters: {'booster': 'gblinear', 'lambda': 0.00016788146789630906, 'alpha': 0.00034545144031176235}. Best is trial 21 with value: 0.9175.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:15:21,133]\u001b[0m Trial 22 finished with value: 0.9122 and parameters: {'booster': 'gblinear', 'lambda': 1.028514409088605e-05, 'alpha': 0.000611650465920119}. Best is trial 21 with value: 0.9175.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:15:46,459]\u001b[0m Trial 23 finished with value: 0.87 and parameters: {'booster': 'gblinear', 'lambda': 1.1749966596589487e-05, 'alpha': 0.02815680293440318}. Best is trial 21 with value: 0.9175.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:16:11,945]\u001b[0m Trial 24 finished with value: 0.9105 and parameters: {'booster': 'gblinear', 'lambda': 0.00040711441504061297, 'alpha': 3.1922707711436977e-05}. Best is trial 21 with value: 0.9175.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:16:37,450]\u001b[0m Trial 25 finished with value: 0.9122 and parameters: {'booster': 'gblinear', 'lambda': 1.7988637041363e-05, 'alpha': 0.0006023062920318102}. Best is trial 21 with value: 0.9175.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:17:50,256]\u001b[0m Trial 26 finished with value: 0.9069 and parameters: {'booster': 'gbtree', 'lambda': 0.00028549483911109784, 'alpha': 0.00046663644732633237, 'max_depth': 5, 'eta': 1.4541152206053428e-08, 'gamma': 0.23661157519020803, 'grow_policy': 'depthwise'}. Best is trial 21 with value: 0.9175.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:18:15,772]\u001b[0m Trial 27 finished with value: 0.9122 and parameters: {'booster': 'gblinear', 'lambda': 3.838470712622631e-08, 'alpha': 4.57076308965215e-06}. Best is trial 21 with value: 0.9175.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:18:41,254]\u001b[0m Trial 28 finished with value: 0.9104 and parameters: {'booster': 'gblinear', 'lambda': 5.165449242184254e-07, 'alpha': 1.8608105165739753e-07}. Best is trial 21 with value: 0.9175.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:19:06,733]\u001b[0m Trial 29 finished with value: 0.914 and parameters: {'booster': 'gblinear', 'lambda': 0.00011602640395389883, 'alpha': 8.230726059967836e-06}. Best is trial 21 with value: 0.9175.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:19:32,191]\u001b[0m Trial 30 finished with value: 0.8841 and parameters: {'booster': 'gblinear', 'lambda': 0.007742998733015813, 'alpha': 7.298435158385209e-06}. Best is trial 21 with value: 0.9175.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:19:57,685]\u001b[0m Trial 31 finished with value: 0.9122 and parameters: {'booster': 'gblinear', 'lambda': 0.00017225198419529262, 'alpha': 6.951750996974373e-05}. Best is trial 21 with value: 0.9175.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:20:23,144]\u001b[0m Trial 32 finished with value: 0.9122 and parameters: {'booster': 'gblinear', 'lambda': 0.0001692818376184164, 'alpha': 7.402717810840724e-05}. Best is trial 21 with value: 0.9175.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:20:48,599]\u001b[0m Trial 33 finished with value: 0.9122 and parameters: {'booster': 'gblinear', 'lambda': 4.613932110215597e-05, 'alpha': 4.149373661742976e-07}. Best is trial 21 with value: 0.9175.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:21:14,082]\u001b[0m Trial 34 finished with value: 0.8735 and parameters: {'booster': 'gblinear', 'lambda': 0.06655493549123984, 'alpha': 1.2592377302051395e-07}. Best is trial 21 with value: 0.9175.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:21:39,521]\u001b[0m Trial 35 finished with value: 0.8823 and parameters: {'booster': 'gblinear', 'lambda': 0.0037051422232598904, 'alpha': 0.00203623371926}. Best is trial 21 with value: 0.9175.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:22:07,217]\u001b[0m Trial 36 finished with value: 0.8647 and parameters: {'booster': 'gbtree', 'lambda': 5.8963055609292025e-08, 'alpha': 7.231409154776821e-06, 'max_depth': 1, 'eta': 0.0002607511169135951, 'gamma': 2.2789602275565806e-06, 'grow_policy': 'lossguide'}. Best is trial 21 with value: 0.9175.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:22:32,619]\u001b[0m Trial 37 finished with value: 0.8981 and parameters: {'booster': 'gblinear', 'lambda': 0.001419734961983672, 'alpha': 8.120449445960918e-05}. Best is trial 21 with value: 0.9175.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:22:58,072]\u001b[0m Trial 38 finished with value: 0.8753 and parameters: {'booster': 'gblinear', 'lambda': 0.021153804830796683, 'alpha': 0.00551250836119606}. Best is trial 21 with value: 0.9175.\u001b[0m\n",
      "\u001b[32m[I 2022-02-17 11:23:23,553]\u001b[0m Trial 39 finished with value: 0.9087 and parameters: {'booster': 'gblinear', 'lambda': 2.5574748965269272e-08, 'alpha': 3.920686801998608e-06}. Best is trial 21 with value: 0.9175.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# execute the study\n",
    "#\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=5)\n",
    "\n",
    "study = optuna.create_study(study_name=EXP_NAME, pruner=pruner, direction=\"maximize\")\n",
    "\n",
    "study.optimize(objective, n_trials=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5033257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: FrozenTrial(number=29, values=[0.9175], datetime_start=datetime.datetime(2022, 2, 17, 11, 4, 5, 353347), datetime_complete=datetime.datetime(2022, 2, 17, 11, 4, 24, 429950), params={'booster': 'gblinear', 'lambda': 5.1047057860194974e-08, 'alpha': 0.001668378974567739}, distributions={'booster': CategoricalDistribution(choices=('gbtree', 'gblinear')), 'lambda': LogUniformDistribution(high=1.0, low=1e-08), 'alpha': LogUniformDistribution(high=1.0, low=1e-08)}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.17039279999999998, 1: 0.1440772, 2: 0.13879840000000002, 3: 0.12293119999999999, 4: 0.11762159999999999, 5: 0.1211614, 6: 0.1211458, 7: 0.1211768, 8: 0.1123584, 9: 0.1211614, 10: 0.1229468, 11: 0.1194224, 12: 0.1194224, 13: 0.11415919999999999, 14: 0.11591359999999999, 15: 0.11591359999999999, 16: 0.1106504, 17: 0.1124048, 18: 0.1036328, 19: 0.1124048, 20: 0.10537179999999999, 21: 0.1036174, 22: 0.10537179999999999, 23: 0.10537179999999999, 24: 0.10184739999999999, 25: 0.10009299999999999, 26: 0.10537179999999999, 27: 0.0983386, 28: 0.10009299999999999, 29: 0.10184739999999999, 30: 0.0965842, 31: 0.09482979999999999, 32: 0.09482979999999999, 33: 0.0983386, 34: 0.0965842, 35: 0.09482979999999999, 36: 0.0930754, 37: 0.0930754, 38: 0.08781219999999999, 39: 0.0895666, 40: 0.08781219999999999, 41: 0.08781219999999999, 42: 0.0895666, 43: 0.08605779999999999, 44: 0.08605779999999999, 45: 0.08605779999999999, 46: 0.08781219999999999, 47: 0.08605779999999999, 48: 0.08605779999999999, 49: 0.08605779999999999, 50: 0.08781219999999999, 51: 0.0843034, 52: 0.0843034, 53: 0.0825336, 54: 0.0825336, 55: 0.0825336, 56: 0.0843034, 57: 0.0843034, 58: 0.0843034, 59: 0.0825336}, trial_id=29, state=TrialState.COMPLETE, value=None)\n"
     ]
    }
   ],
   "source": [
    "# analyze result\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"Best trial:\", trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57111c91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
